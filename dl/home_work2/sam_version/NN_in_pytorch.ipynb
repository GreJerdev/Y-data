{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network using PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, you will build a neural network using PyTorch, and apply it to a dataset. Our goal in this exercise is not necessarily to obtain the best results on the dataset. We care more about understanding the different parameters, getting a hands-on experience training networks, and monitoring and debugging them. For this reason, I actually recommend that you donâ€™t use a GPU, and run the code on your local machine, for simpler debugging.\n",
    "\n",
    "\n",
    "You can get relevant code snippets from [the PyTorch documentation](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html) or other sources online. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "We will use the CIFAR-10 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T03:22:05.577442Z",
     "start_time": "2020-03-12T03:22:04.944943Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T03:22:07.447520Z",
     "start_time": "2020-03-12T03:22:05.580433Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b4398c6c4614306b2b2ec3af600c3cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset CIFAR10\n",
      "    Number of datapoints: 50000\n",
      "    Root location: ./data\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               ToTensor()\n",
      "               Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "print(trainset)\n",
    "# print(classes)\n",
    "# print(trainset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'int' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-222606eff948>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#     qty = trainset.targets[trainset.targets==i].shape[0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mqty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{trainset.classes[i]} {qty}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'int' has no len()"
     ]
    }
   ],
   "source": [
    "for i in range(len(trainset.classes)):\n",
    "#     qty = trainset.targets[trainset.targets==i].shape[0]\n",
    "    qty = len(trainset.targets[i])\n",
    "    print(f\"{trainset.classes[i]} {qty}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's get to know the dataset. Plot a few examples of images and their labels:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ship  frog   car   cat\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the distribution of images per label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T03:22:13.668056Z",
     "start_time": "2020-03-12T03:22:13.185607Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "car      5000\n",
       "ship     5000\n",
       "frog     5000\n",
       "dog      5000\n",
       "bird     5000\n",
       "plane    5000\n",
       "cat      5000\n",
       "horse    5000\n",
       "deer     5000\n",
       "truck    5000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is the data balanced? What effect is imbalanced data expected to have on your model's results? How can you work with imbalanced data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer\n",
    "\n",
    "Yes, the data is balance, \n",
    "\n",
    "The unbalanced classes create a problem due to two main reasons:\n",
    "\n",
    "- We donâ€™t get optimized results for the class which is unbalanced in real time as the model/algorithm never gets sufficient look at the underlying class\n",
    "\n",
    "- It creates a problem of making a validation or test sample as its difficult to have representation across classes in case number of observation for few classes is extremely less\n",
    "\n",
    "There are three main approaches to work with imbalanced data, each having its pros and cons:\n",
    "\n",
    "- Undersampling- Randomly delete the class which has sufficient observations so that the comparative ratio of two classes is significant in our data.Although this approach is really simple to follow but there is a high possibility that the data that we are deleting may contain important information about the predictive class.\n",
    "\n",
    "- Oversampling-For the unbalanced class randomly increase the number of observations which are just copies of existing samples.This ideally gives us sufficient number of samples to play with.The oversampling may lead to overfitting to the training data\n",
    "\n",
    "- Synthetic sampling(SMOTE)-The technique asks to synthetically manufacture observations of unbalanced classes which are similar to the existing using nearest neighbors classification.The problem is what to do when the number of observations of is an extremely rare class .For example-we may have only one picture of a rare species which we want to identify using image classification algorithm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** It's a good practice when working on Neural Networks to start with a very small dataset and overfit on it. While we don't specifically ask you to do so in the sections below, we recommend that you take this approach, and first write and run your code using easy to use and debug platform, on a small dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build your own CNN classifier\n",
    "In this section, you will develop your own CNN classifier.\n",
    "\n",
    "This is meant as an opportunity to get more experience building your own NN architectures using PyTorch, and our focus is on making sure you rewrite and review the needed code and not on obtaining optimal performance. That being said, within the limits of the time you have, try to come up with a NN architecture and hyperparameters that would achieve nice results on the dataset.  \n",
    "We do recommend that you keep this to only 3-4 Conv layers and 1-2 fully connected layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want a starting point, you can create this network:\n",
    "\n",
    "```\n",
    "Net(\n",
    "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
    "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
    "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
    "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
    "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When training the network, use the Adam optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T03:22:14.105625Z",
     "start_time": "2020-03-12T03:22:14.096637Z"
    }
   },
   "outputs": [],
   "source": [
    "# for evaluating the model\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# PyTorch libraries and modules\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\n",
    "from torch.optim import Adam, SGD\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T03:22:14.719122Z",
     "start_time": "2020-03-12T03:22:14.715095Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "train_x = trainset.data.reshape(50000, 3, 32, 32).astype(np.int32)\n",
    "train_x  = torch.from_numpy(train_x)\n",
    "\n",
    "train_y = np.array(trainset.targets);\n",
    "train_y = torch.from_numpy(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting validation images into torch format\n",
    "val_x = testset.data.reshape(10000, 3, 32, 32)\n",
    "val_x  = torch.from_numpy(val_x)\n",
    "\n",
    "# converting the target into torch format\n",
    "val_y = np.array(testset.targets);\n",
    "val_y = torch.from_numpy(val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(Module):   \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.cnn_layers = Sequential(\n",
    "            \n",
    "        Conv2d(3, 6, kernel_size=(3, 3), stride=(1, 1)),\n",
    "        BatchNorm2d(6),\n",
    "        ReLU(inplace=True),\n",
    "        MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
    "        Conv2d(6, 24, kernel_size=(5, 5), stride=(1, 1)),\n",
    "        BatchNorm2d(24),\n",
    "        ReLU(inplace=True),\n",
    "        MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
    "        Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1),padding=2),\n",
    "        BatchNorm2d(64),\n",
    "        ReLU(inplace=True),\n",
    "        Conv2d(64, 48, kernel_size=(1, 1), stride=(1, 1),padding=2),\n",
    "        BatchNorm2d(48),\n",
    "        ReLU(inplace=True),    \n",
    "        MaxPool2d(kernel_size=2, stride=2)            \n",
    "        \n",
    "\n",
    "        )\n",
    "        self.drop_out = Dropout()\n",
    "        self.fc1 = Linear(in_features=1200, out_features=120, bias=True)\n",
    "        self.fc2 = Linear(in_features=120, out_features=84, bias=True)\n",
    "        self.fc3 = Linear(in_features=84, out_features=10, bias=True)\n",
    "        self.softmax = Softmax(dim=1)\n",
    "\n",
    "    # Defining the forward pass    \n",
    "    def forward(self, input):\n",
    "      \n",
    "        output = self.cnn_layers(input)\n",
    "        output = self.drop_out(output)\n",
    "       \n",
    "        output = output.view(output.size(0),  48* 5* 5)\n",
    "       \n",
    "        output = self.fc1(output)\n",
    "        output = F.relu(self.fc2(output))\n",
    "        output = self.softmax(self.fc3(output))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (cnn_layers): Sequential(\n",
      "    (0): Conv2d(3, 6, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv2d(6, 24, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (5): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (8): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "    (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): ReLU(inplace=True)\n",
      "    (11): Conv2d(64, 48, kernel_size=(1, 1), stride=(1, 1), padding=(2, 2))\n",
      "    (12): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (drop_out): Dropout(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=1200, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "  (softmax): Softmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#call this model, and define the optimizer and the loss function for the model\n",
    "# defining the model\n",
    "model = Net()\n",
    "# defining the optimizer (Adam optimizer)\n",
    "optimizer = Adam(model.parameters(), lr=0.001)\n",
    "# defining the loss function\n",
    "criterion = CrossEntropyLoss()\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time:20:59:18,  epoch [1/100],  Loss: 2.3033, Accuracy: 9.96%/0.10  correct:498 ,total 5000\n",
      "time:20:59:23,  epoch [2/100],  Loss: 2.2960, Accuracy: 14.60%/0.15  correct:730 ,total 5000\n",
      "time:20:59:27,  epoch [3/100],  Loss: 2.2872, Accuracy: 14.04%/0.14  correct:702 ,total 5000\n",
      "time:20:59:31,  epoch [4/100],  Loss: 2.2757, Accuracy: 17.00%/0.17  correct:850 ,total 5000\n",
      "time:20:59:35,  epoch [5/100],  Loss: 2.2628, Accuracy: 20.86%/0.21  correct:1043 ,total 5000\n",
      "time:20:59:39,  epoch [6/100],  Loss: 2.2520, Accuracy: 20.42%/0.20  correct:1021 ,total 5000\n",
      "time:20:59:44,  epoch [7/100],  Loss: 2.2395, Accuracy: 21.78%/0.22  correct:1089 ,total 5000\n",
      "time:20:59:48,  epoch [8/100],  Loss: 2.2288, Accuracy: 22.82%/0.23  correct:1141 ,total 5000\n",
      "time:20:59:53,  epoch [9/100],  Loss: 2.2199, Accuracy: 23.66%/0.24  correct:1183 ,total 5000\n",
      "time:20:59:58,  epoch [10/100],  Loss: 2.2146, Accuracy: 23.10%/0.23  correct:1155 ,total 5000\n",
      "time:21:00:02,  epoch [11/100],  Loss: 2.2064, Accuracy: 23.60%/0.24  correct:1180 ,total 5000\n",
      "time:21:00:06,  epoch [12/100],  Loss: 2.2001, Accuracy: 24.66%/0.25  correct:1233 ,total 5000\n",
      "time:21:00:11,  epoch [13/100],  Loss: 2.1935, Accuracy: 25.20%/0.25  correct:1260 ,total 5000\n",
      "time:21:00:15,  epoch [14/100],  Loss: 2.1888, Accuracy: 26.18%/0.26  correct:1309 ,total 5000\n",
      "time:21:00:19,  epoch [15/100],  Loss: 2.1806, Accuracy: 27.14%/0.27  correct:1357 ,total 5000\n",
      "time:21:00:24,  epoch [16/100],  Loss: 2.1761, Accuracy: 27.60%/0.28  correct:1380 ,total 5000\n",
      "time:21:00:28,  epoch [17/100],  Loss: 2.1709, Accuracy: 28.30%/0.28  correct:1415 ,total 5000\n",
      "time:21:00:32,  epoch [18/100],  Loss: 2.1641, Accuracy: 28.76%/0.29  correct:1438 ,total 5000\n",
      "time:21:00:37,  epoch [19/100],  Loss: 2.1584, Accuracy: 29.30%/0.29  correct:1465 ,total 5000\n",
      "time:21:00:41,  epoch [20/100],  Loss: 2.1508, Accuracy: 30.26%/0.30  correct:1513 ,total 5000\n",
      "time:21:00:45,  epoch [21/100],  Loss: 2.1455, Accuracy: 31.16%/0.31  correct:1558 ,total 5000\n",
      "time:21:00:50,  epoch [22/100],  Loss: 2.1401, Accuracy: 31.52%/0.32  correct:1576 ,total 5000\n",
      "time:21:00:54,  epoch [23/100],  Loss: 2.1343, Accuracy: 32.14%/0.32  correct:1607 ,total 5000\n",
      "time:21:00:59,  epoch [24/100],  Loss: 2.1311, Accuracy: 32.94%/0.33  correct:1647 ,total 5000\n",
      "time:21:01:03,  epoch [25/100],  Loss: 2.1279, Accuracy: 32.88%/0.33  correct:1644 ,total 5000\n",
      "time:21:01:07,  epoch [26/100],  Loss: 2.1228, Accuracy: 32.98%/0.33  correct:1649 ,total 5000\n",
      "time:21:01:11,  epoch [27/100],  Loss: 2.1211, Accuracy: 33.36%/0.33  correct:1668 ,total 5000\n",
      "time:21:01:15,  epoch [28/100],  Loss: 2.1170, Accuracy: 33.66%/0.34  correct:1683 ,total 5000\n",
      "time:21:01:20,  epoch [29/100],  Loss: 2.1125, Accuracy: 34.66%/0.35  correct:1733 ,total 5000\n",
      "time:21:01:24,  epoch [30/100],  Loss: 2.1085, Accuracy: 34.96%/0.35  correct:1748 ,total 5000\n",
      "time:21:01:28,  epoch [31/100],  Loss: 2.1049, Accuracy: 35.32%/0.35  correct:1766 ,total 5000\n",
      "time:21:01:32,  epoch [32/100],  Loss: 2.0994, Accuracy: 35.60%/0.36  correct:1780 ,total 5000\n",
      "time:21:01:37,  epoch [33/100],  Loss: 2.0963, Accuracy: 36.32%/0.36  correct:1816 ,total 5000\n",
      "time:21:01:41,  epoch [34/100],  Loss: 2.0944, Accuracy: 36.76%/0.37  correct:1838 ,total 5000\n",
      "time:21:01:46,  epoch [35/100],  Loss: 2.0925, Accuracy: 36.58%/0.37  correct:1829 ,total 5000\n",
      "time:21:01:50,  epoch [36/100],  Loss: 2.0880, Accuracy: 37.58%/0.38  correct:1879 ,total 5000\n",
      "time:21:01:54,  epoch [37/100],  Loss: 2.0843, Accuracy: 37.50%/0.38  correct:1875 ,total 5000\n",
      "time:21:01:59,  epoch [38/100],  Loss: 2.0842, Accuracy: 37.42%/0.37  correct:1871 ,total 5000\n",
      "time:21:02:03,  epoch [39/100],  Loss: 2.0828, Accuracy: 37.50%/0.38  correct:1875 ,total 5000\n",
      "time:21:02:08,  epoch [40/100],  Loss: 2.0794, Accuracy: 37.92%/0.38  correct:1896 ,total 5000\n",
      "time:21:02:12,  epoch [41/100],  Loss: 2.0719, Accuracy: 38.90%/0.39  correct:1945 ,total 5000\n",
      "time:21:02:16,  epoch [42/100],  Loss: 2.0720, Accuracy: 38.90%/0.39  correct:1945 ,total 5000\n",
      "time:21:02:21,  epoch [43/100],  Loss: 2.0676, Accuracy: 38.84%/0.39  correct:1942 ,total 5000\n",
      "time:21:02:25,  epoch [44/100],  Loss: 2.0669, Accuracy: 39.06%/0.39  correct:1953 ,total 5000\n",
      "time:21:02:30,  epoch [45/100],  Loss: 2.0599, Accuracy: 40.40%/0.40  correct:2020 ,total 5000\n",
      "time:21:02:34,  epoch [46/100],  Loss: 2.0645, Accuracy: 40.06%/0.40  correct:2003 ,total 5000\n",
      "time:21:02:38,  epoch [47/100],  Loss: 2.0612, Accuracy: 39.96%/0.40  correct:1998 ,total 5000\n",
      "time:21:02:43,  epoch [48/100],  Loss: 2.0587, Accuracy: 40.38%/0.40  correct:2019 ,total 5000\n",
      "time:21:02:47,  epoch [49/100],  Loss: 2.0536, Accuracy: 40.66%/0.41  correct:2033 ,total 5000\n",
      "time:21:02:51,  epoch [50/100],  Loss: 2.0520, Accuracy: 40.84%/0.41  correct:2042 ,total 5000\n",
      "time:21:02:55,  epoch [51/100],  Loss: 2.0474, Accuracy: 41.40%/0.41  correct:2070 ,total 5000\n",
      "time:21:02:59,  epoch [52/100],  Loss: 2.0459, Accuracy: 41.78%/0.42  correct:2089 ,total 5000\n",
      "time:21:03:04,  epoch [53/100],  Loss: 2.0453, Accuracy: 41.48%/0.41  correct:2074 ,total 5000\n",
      "time:21:03:09,  epoch [54/100],  Loss: 2.0434, Accuracy: 41.92%/0.42  correct:2096 ,total 5000\n",
      "time:21:03:13,  epoch [55/100],  Loss: 2.0396, Accuracy: 42.44%/0.42  correct:2122 ,total 5000\n",
      "time:21:03:17,  epoch [56/100],  Loss: 2.0344, Accuracy: 43.08%/0.43  correct:2154 ,total 5000\n",
      "time:21:03:22,  epoch [57/100],  Loss: 2.0349, Accuracy: 42.62%/0.43  correct:2131 ,total 5000\n",
      "time:21:03:26,  epoch [58/100],  Loss: 2.0345, Accuracy: 42.96%/0.43  correct:2148 ,total 5000\n",
      "time:21:03:30,  epoch [59/100],  Loss: 2.0305, Accuracy: 43.34%/0.43  correct:2167 ,total 5000\n",
      "time:21:03:34,  epoch [60/100],  Loss: 2.0266, Accuracy: 43.94%/0.44  correct:2197 ,total 5000\n",
      "time:21:03:38,  epoch [61/100],  Loss: 2.0221, Accuracy: 44.24%/0.44  correct:2212 ,total 5000\n",
      "time:21:03:43,  epoch [62/100],  Loss: 2.0242, Accuracy: 44.14%/0.44  correct:2207 ,total 5000\n",
      "time:21:03:47,  epoch [63/100],  Loss: 2.0246, Accuracy: 43.80%/0.44  correct:2190 ,total 5000\n",
      "time:21:03:51,  epoch [64/100],  Loss: 2.0202, Accuracy: 44.14%/0.44  correct:2207 ,total 5000\n",
      "time:21:03:56,  epoch [65/100],  Loss: 2.0120, Accuracy: 45.58%/0.46  correct:2279 ,total 5000\n",
      "time:21:04:00,  epoch [66/100],  Loss: 2.0125, Accuracy: 44.88%/0.45  correct:2244 ,total 5000\n",
      "time:21:04:04,  epoch [67/100],  Loss: 2.0102, Accuracy: 45.46%/0.45  correct:2273 ,total 5000\n",
      "time:21:04:08,  epoch [68/100],  Loss: 2.0130, Accuracy: 45.10%/0.45  correct:2255 ,total 5000\n",
      "time:21:04:13,  epoch [69/100],  Loss: 2.0161, Accuracy: 44.58%/0.45  correct:2229 ,total 5000\n",
      "time:21:04:17,  epoch [70/100],  Loss: 2.0069, Accuracy: 46.18%/0.46  correct:2309 ,total 5000\n",
      "time:21:04:21,  epoch [71/100],  Loss: 2.0090, Accuracy: 45.48%/0.45  correct:2274 ,total 5000\n",
      "time:21:04:25,  epoch [72/100],  Loss: 1.9990, Accuracy: 46.96%/0.47  correct:2348 ,total 5000\n",
      "time:21:04:29,  epoch [73/100],  Loss: 2.0012, Accuracy: 46.02%/0.46  correct:2301 ,total 5000\n",
      "time:21:04:34,  epoch [74/100],  Loss: 2.0001, Accuracy: 46.54%/0.47  correct:2327 ,total 5000\n",
      "time:21:04:38,  epoch [75/100],  Loss: 1.9995, Accuracy: 46.44%/0.46  correct:2322 ,total 5000\n",
      "time:21:04:42,  epoch [76/100],  Loss: 1.9925, Accuracy: 47.42%/0.47  correct:2371 ,total 5000\n",
      "time:21:04:47,  epoch [77/100],  Loss: 1.9994, Accuracy: 46.28%/0.46  correct:2314 ,total 5000\n",
      "time:21:04:51,  epoch [78/100],  Loss: 1.9942, Accuracy: 46.70%/0.47  correct:2335 ,total 5000\n",
      "time:21:04:56,  epoch [79/100],  Loss: 1.9892, Accuracy: 47.36%/0.47  correct:2368 ,total 5000\n",
      "time:21:05:00,  epoch [80/100],  Loss: 1.9911, Accuracy: 47.28%/0.47  correct:2364 ,total 5000\n",
      "time:21:05:04,  epoch [81/100],  Loss: 1.9891, Accuracy: 47.74%/0.48  correct:2387 ,total 5000\n",
      "time:21:05:08,  epoch [82/100],  Loss: 1.9873, Accuracy: 47.36%/0.47  correct:2368 ,total 5000\n",
      "time:21:05:13,  epoch [83/100],  Loss: 1.9831, Accuracy: 48.40%/0.48  correct:2420 ,total 5000\n",
      "time:21:05:17,  epoch [84/100],  Loss: 1.9879, Accuracy: 47.32%/0.47  correct:2366 ,total 5000\n",
      "time:21:05:21,  epoch [85/100],  Loss: 1.9867, Accuracy: 47.54%/0.48  correct:2377 ,total 5000\n",
      "time:21:05:25,  epoch [86/100],  Loss: 1.9825, Accuracy: 48.70%/0.49  correct:2435 ,total 5000\n",
      "time:21:05:29,  epoch [87/100],  Loss: 1.9773, Accuracy: 49.06%/0.49  correct:2453 ,total 5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time:21:05:36,  epoch [88/100],  Loss: 1.9824, Accuracy: 48.20%/0.48  correct:2410 ,total 5000\n",
      "time:21:05:40,  epoch [89/100],  Loss: 1.9770, Accuracy: 48.98%/0.49  correct:2449 ,total 5000\n",
      "time:21:05:45,  epoch [90/100],  Loss: 1.9815, Accuracy: 48.36%/0.48  correct:2418 ,total 5000\n",
      "time:21:05:50,  epoch [91/100],  Loss: 1.9714, Accuracy: 49.32%/0.49  correct:2466 ,total 5000\n",
      "time:21:05:54,  epoch [92/100],  Loss: 1.9765, Accuracy: 48.72%/0.49  correct:2436 ,total 5000\n",
      "time:21:05:58,  epoch [93/100],  Loss: 1.9681, Accuracy: 49.76%/0.50  correct:2488 ,total 5000\n",
      "time:21:06:03,  epoch [94/100],  Loss: 1.9732, Accuracy: 48.96%/0.49  correct:2448 ,total 5000\n",
      "time:21:06:07,  epoch [95/100],  Loss: 1.9633, Accuracy: 50.18%/0.50  correct:2509 ,total 5000\n",
      "time:21:06:11,  epoch [96/100],  Loss: 1.9658, Accuracy: 50.12%/0.50  correct:2506 ,total 5000\n",
      "time:21:06:15,  epoch [97/100],  Loss: 1.9700, Accuracy: 49.16%/0.49  correct:2458 ,total 5000\n",
      "time:21:06:19,  epoch [98/100],  Loss: 1.9595, Accuracy: 50.68%/0.51  correct:2534 ,total 5000\n",
      "time:21:06:24,  epoch [99/100],  Loss: 1.9625, Accuracy: 50.30%/0.50  correct:2515 ,total 5000\n",
      "time:21:06:28,  epoch [100/100],  Loss: 1.9619, Accuracy: 50.38%/0.50  correct:2519 ,total 5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method SummaryWriter.close of <torch.utils.tensorboard.writer.SummaryWriter object at 0x144591048>>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "import time\n",
    "time.strftime('%X')\n",
    "num_epochs = 100\n",
    "total_step = int(train_x.shape[0]/num_epochs)\n",
    "loss_list = []\n",
    "acc_list = []\n",
    "writer = SummaryWriter()\n",
    "\n",
    "model.train()\n",
    "\n",
    "items = np.arange(train_x.shape[0])\n",
    "items_index = np.random.choice(items, size=5000, replace=False)\n",
    "x_train, y_train = Variable(train_x), Variable(train_y)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    # Run the forward pass\n",
    "\n",
    "    outputs = model.forward(train_x[items_index].float())\n",
    "    loss = criterion(outputs, train_y[items_index])\n",
    "\n",
    "    # Backprop and perform Adam optimisation\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    loss_list.append(loss.item())\n",
    "    # Track the accuracy\n",
    "    total =  train_y[items_index].size(0)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    correct = (predicted == train_y[items_index]).sum().item()\n",
    "    acc_list.append(correct / total)\n",
    "    # Compute accuracy\n",
    "    _, argmax = torch.max(outputs, 1)\n",
    "    accuracy = (train_y[items_index] == argmax.squeeze()).float().mean()\n",
    "\n",
    "    if (epoch) % 1 == 0:\n",
    "        print('time:{},  epoch [{}/{}],  Loss: {:.4f}, Accuracy: {:.2f}%/{:.2f}  correct:{} ,total {}'\n",
    "          .format(time.strftime('%X'), epoch + 1,num_epochs,loss.item(),\n",
    "                  (correct / total) * 100,accuracy.item(),correct , total))\n",
    "\n",
    "        # ================================================================== #\n",
    "        #                        Tensorboard Logging                         #\n",
    "        # ================================================================== #\n",
    "\n",
    "        # 1. Log scalar values (scalar summary)\n",
    "        info = { 'loss': loss.item(), 'accuracy': accuracy.item() }\n",
    "\n",
    "        for tag, value in info.items():\n",
    "        #    print(tag, value)\n",
    "            writer.add_scalar(tag, value, epoch+1)\n",
    "\n",
    "        # 2. Log values and gradients of the parameters (histogram summary)\n",
    "        for tag, value in model.named_parameters():\n",
    "            tag = tag.replace('.', '/')\n",
    "            writer.add_histogram(tag, value.data.cpu().numpy(), epoch+1)\n",
    "            writer.add_histogram(tag+'/grad', value.grad.data.cpu().numpy(), epoch+1)\n",
    "\n",
    "        # 3. Log training images (image summary)\n",
    "        info = { 'images': train_x[items_index].view(-1,3,32, 32)[:10].cpu().numpy() }\n",
    "        info = { 'images': train_x[items_index][:10].cpu().numpy() }\n",
    "\n",
    "        for tag, images in info.items():\n",
    "            writer.add_images(tag, images, epoch+1)     \n",
    "writer.add_graph(model, train_x[items_index].float())  \n",
    "writer.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3de1hVVfrA8e97uCogCKIooHhXUETEu2la460mzRy11JomM8uZ7NdtnKaZppppypmxdMZSu2qZ1qiVOaXTRdPyCt4FFbyDKHhDRFAOrN8f5+iggoCC53DO+3me83DO3mvv8652vizWXnstMcaglFLKdVkcHYBSSqnqpYleKaVcnCZ6pZRycZrolVLKxWmiV0opF+fp6ABKU69ePRMVFeXoMJRSqsZISko6bowJLW2fUyb6qKgoEhMTHR2GUkrVGCJysKx92nWjlFIuThO9Ukq5OE30Sinl4pyyj14p5XwKCwtJT0+noKDA0aG4NV9fXyIiIvDy8qrwMZrolVIVkp6eTkBAAFFRUYiIo8NxS8YYTpw4QXp6Ok2bNq3wcdp1o5SqkIKCAkJCQjTJO5CIEBISUum/qjTRK6UqTJO8413PNSg30YtIpIisEJFkEdkpIpNKKTNERLaJyBYRSRSRXiX2PSAiqfbXA5WOsIKKig0zVqSxLf10dX2FUkrVSBVp0VuBp4wx0UA3YKKIRF9R5juggzEmDvgV8A6AiAQDLwBdgS7ACyJSt6qCL+nseSvz1h3kN/M3k1tQWB1foZRyoBMnThAXF0dcXBxhYWGEh4df+nzhwoUKnePBBx9k9+7d1ywzY8YM5s2bVxUh06tXL7Zs2VIl57oR5d6MNcZkApn297kikgKEA8klypwtcYgfcHE1kwHAN8aYkwAi8g0wEJhfJdGXEFjLizdGdWTU7LX84fMdvD4yTv/MVMqFhISEXEqaf/rTn/D39+fpp5++rIwxBmMMFkvpbdj333+/3O+ZOHHijQfrZCrVRy8iUUBHYH0p++4WkV3Af7C16sH2C+FwiWLp9m2lnXu8vdsnMTs7uzJhXdKlaTCTbmvF51uOsGhTxnWdQylVs6SlpREdHc3o0aOJiYkhMzOT8ePHk5CQQExMDC+99NKlshdb2FarlaCgICZPnkyHDh3o3r07WVlZADz//PO88cYbl8pPnjyZLl260Lp1a9asWQNAXl4e99xzD9HR0QwfPpyEhIRyW+4fffQR7du3p127djz33HMAWK1Wxo4de2n79OnTAXj99deJjo4mNjaWMWPG3PB/owoPrxQRf2AR8IQx5syV+40xnwGfiUhv4GXg9soEYoyZDcwGSEhIuO71DX/drwVr9h7nj1/sIL5xEM1C/a/3VEqpMrz45U6Sj1yVBm5IdKM6vPDzmOs6dteuXcydO5eEhAQAXn31VYKDg7FarfTt25fhw4cTHX15j3NOTg59+vTh1Vdf5cknn+S9995j8uTJV53bGMOGDRtYsmQJL730EsuWLeOf//wnYWFhLFq0iK1btxIfH3/N+NLT03n++edJTEwkMDCQ22+/naVLlxIaGsrx48fZvn07AKdP2+4xTpkyhYMHD+Lt7X1p242oUIteRLywJfl5xpjF1yprjFkFNBORekAGEFlid4R9W7XxsAhvjIrD29PCMwu3UVysa+Iq5eqaN29+KckDzJ8/n/j4eOLj40lJSSE5OfmqY2rVqsWgQYMA6NSpEwcOHCj13MOGDbuqzI8//sioUaMA6NChAzEx1/4FtX79evr160e9evXw8vLivvvuY9WqVbRo0YLdu3fz+OOPs3z5cgIDAwGIiYlhzJgxzJs3r1IPRpWl3Ba92Dq63wVSjDFTyyjTAthrjDEiEg/4ACeA5cArJW7A9gd+d8NRl6NhYC1+P7gtzyzcxsKkdEZ0jiz/IKVUhV1vy7u6+Pn5XXqfmprKtGnT2LBhA0FBQYwZM6bUcefe3t6X3nt4eGC1Wks9t4+PT7llrldISAjbtm3j66+/ZsaMGSxatIjZs2ezfPlyfvjhB5YsWcIrr7zCtm3b8PDwuO7vqUiLvicwFuhnHz65RUQGi8gEEZlgL3MPsENEtgAzgJHG5iS2bpyN9tdLF2/MVrd74iPoHFWXv36dwqm8it2RV0rVfGfOnCEgIIA6deqQmZnJ8uXLq/w7evbsyaeffgrA9u3bS/2LoaSuXbuyYsUKTpw4gdVqZcGCBfTp04fs7GyMMfziF7/gpZdeYtOmTRQVFZGenk6/fv2YMmUKx48f59y5czcUb0VG3fwIXHP4ijHmNeC1Mva9B7x3XdHdAItFeHloO+6Y/iNTlu/ir8Nib3YISikHiI+PJzo6mjZt2tCkSRN69uxZ5d/xm9/8hvvvv5/o6OhLr4vdLqWJiIjg5Zdf5tZbb8UYw89//nPuuOMONm3axEMPPYQxBhHhtddew2q1ct9995Gbm0txcTFPP/00AQEBNxSvGON8fdgJCQmmqhYe+ct/knl79X4WP9aD+MbVMoRfKbeQkpJC27ZtHR2GU7BarVitVnx9fUlNTaV///6kpqbi6Xlzpg8r7VqISJIxJqG08i4/qdkTt7fiy62Z/OU/KSx6tIejw1FKuYCzZ89y2223YbVaMcYwa9asm5bkr4fzRlZF/Hw8efTW5rywZCcbD5ykc1Swo0NSStVwQUFBJCUlOTqMCnOLSc1GJEQS7OfNzJV7HR2KUjWaM3b1upvruQZukehreXvwQPcovtuVxe6juY4OR6kaydfXlxMnTmiyd6CL89H7+vpW6jiX77q56P7uTZj5w15mrdrL1BFxjg5HqRonIiKC9PR0rneKElU1Lq4wVRluk+jr+nkzqkskH649yFP9WxMeVMvRISlVo3h5eVVqVSPlPNyi6+aih3o1xQDvrt7v6FCUUuqmcatEH1G3NnfGNuTTxMPkna/aR5mVUspZuVWiB7i/exRnz1v5fItOY6yUcg9ul+jjGwcR3bAOH649qKMHlFJuwe0SvYgwtnsTdh3NJfHgKUeHo5RS1c7tEj3AkLhGBPh68uHag44ORSmlqp1bJvra3p4M7xTB1zsyyc497+hwlFKqWrllogcY060JhUWGTxMPl19YKaVqMLdN9M1D/enZIoQP1x7kvLXI0eEopVS1cdtED/BonxYcPVPAvxPTHR2KUkpVG7dO9D1bhBDfOIi3Vu7lgrXY0eEopVS1cOtELyI8fltLMk7ns3iTtuqVUq7JrRM9QJ9WoXSICGTGyjQKi7RVr5RyPeUmehGJFJEVIpIsIjtFZFIpZUaLyDYR2S4ia0SkQ4l9B+zbt4hI1SwEW4UutuoPn8zn8806LYJSyvVUpEVvBZ4yxkQD3YCJIhJ9RZn9QB9jTHvgZWD2Ffv7GmPiylq41tH6talPTKM6vLlyL8XFOi2CUsq1lJvojTGZxphN9ve5QAoQfkWZNcaYi/MJrAMqNyu+g4kIE/o0Z//xPH7Yo4sqKKVcS6X66EUkCugIrL9GsYeAr0t8NsB/RSRJRMZf49zjRSRRRBIdsYLNwHZhNKjjw/trDtz071ZKqepU4UQvIv7AIuAJY8yZMsr0xZbof1ticy9jTDwwCFu3T+/SjjXGzDbGJBhjEkJDQytcgari5WFhdNcmrNqTzd7sszf9+5VSqrpUKNGLiBe2JD/PGLO4jDKxwDvAEGPMiYvbjTEZ9p9ZwGdAlxsNurrc26Ux3h4W5mqrXinlQioy6kaAd4EUY8zUMso0BhYDY40xe0ps9xORgIvvgf7AjqoIvDqEBvhwZ2xDFialk1tQ6OhwlFKqSlSkRd8TGAv0sw+R3CIig0VkgohMsJf5IxACvHnFMMoGwI8ishXYAPzHGLOsqitRlR7oEUXehSIWJukDVEop1+BZXgFjzI+AlFNmHDCulO37gA5XH+G8OkQG0bFxEHPXHuT+7lF4WK5ZdaWUcnpu/2RsaR6+pRn7j+exdNsRR4eilFI3TBN9KQbGhNEmLIDp36VSpA9QKaVqOE30pbBYhEm3tWRvdh5fbtVWvVKqZtNEX4YBJVr1Vp3sTClVg2miL4PFIjxxe0v2Hc9jibbqlVI1mCb6a+gfHUbbhnWY/l2qTmGslKqxNNFfg8UiPN2/FQdOnGOOPi2rlKqhNNGXo1+b+vRtHcrr3+zh2JkCR4ejlFKVpom+HCLCn+6KobDY8MpXKY4ORymlKk0TfQU0CfFjQu9mfLHlCOv2nSj/AKWUciKa6Cvo0VtbEB5Uixe+2ElBYZGjw1FKqQrTRF9Btbw9eGlIDLuP5fLw3ERN9kqpGkMTfSXc1rYBU+6J5ce04zw8N5H8C5rslVLOTxN9JY3oHHkp2Y+bu5HzVk32Sinnpon+OvwiIZK/De/AT2knmP5dqqPDUUqpa9JEf52Gd4pgeKcIZv6wjx0ZOY4ORymlyqSJ/gb84Y5ogv28eWbhNp0iQSnltDTR34DA2l78ZWg7UjLPMHPlXkeHo5RSpdJEf4P6x4RxZ2xDpn+fql04SimnVG6iF5FIEVkhIskislNEJpVSZrSIbBOR7SKyRkQ6lNg3UER2i0iaiEyu6go4gxfviqGevw8Pz00kS+fDUUo5mYq06K3AU8aYaKAbMFFEoq8osx/oY4xpD7wMzAYQEQ9gBjAIiAbuLeXYGi/E34d3HkggJ7+Qhz9M0oeplFJOpdxEb4zJNMZssr/PBVKA8CvKrDHGnLJ/XAdE2N93AdKMMfuMMReABcCQqgremcQ0CuSNkXFsSz/NU//eSrGuNauUchKV6qMXkSigI7D+GsUeAr62vw8HDpfYl84VvyRcSf+YMCYPbMN/tmUy/XsdX6+Ucg6eFS0oIv7AIuAJY8yZMsr0xZboe1U2EBEZD4wHaNy4cWUPdxrjezdjz7GzvPFtKm3CAhjYrqGjQ1JKubkKtehFxAtbkp9njFlcRplY4B1giDHm4ly+GUBkiWIR9m1XMcbMNsYkGGMSQkNDKxq/0xER/nJ3O+Iig3jy062kZJb6O1EppW6aioy6EeBdIMUYM7WMMo2BxcBYY8yeErs2Ai1FpKmIeAOjgCU3HrZz8/XyYPbYTgT4evLw3EROnD3v6JCUUm6sIi36nsBYoJ+IbLG/BovIBBGZYC/zRyAEeNO+PxHAGGMFfg0sx3YT91NjzM6qr4bzqV/Hl9ljE8jOPc8vZq3l8Mlzjg5JKeWmxBjnGx2SkJBgEhMTHR1Gldiw/yTj5mzEx8uDDx7sTEyjQEeHpJRyQSKSZIxJKG2fPhlbzbo0DWbhoz3wtAgjZ60j6eBJR4eklHIzmuhvglYNAlj8WA9C/L2ZtGALeeetjg5JKeVGNNHfJA0Da/GPX3Qg43Q+U5btcnQ4Sik3oon+JkqICuaB7lHMWXuQDfu1C0cpdXNoor/Jnh3YmsjgWjy7cKuuOauUuik00d9ktb09eW1YLAdOnOPphVt1AjSlVLXTRO8APVrUY/Ig25w4Y95Zrw9UKaWqlSZ6B5nQpzkz7otne0YOQ9/8idRjuY4OSSnlojTRO9AdsQ355JHu5F8oZsSstew8oitUKaWqniZ6B4uLDGLhhO7U8vLgvrfXsz1dk71SqmpponcCUfX8+OSR7gT4enLfO+vYfOhU+QcppVQFaaJ3EpHBtfnkke7Ure3NuDmJHDmd7+iQlFIuQhO9EwkPqsX7D3bmvLWYRz/StWeVUlVDE72TaR7qzz9GdGBreg4vfukWMzorpaqZJnonNCAmjIl9mzN/w2E+Xn/I0eEopWo4TfRO6smftaZ3q1D+8MUOvk0+5uhwlFI1mCZ6J+VhEd4cHU+7RnV47ONNrNt3ovyDlFKqFJronZi/jyfvP9iFxsG1GTcnkR0ZOsZeKVV5muidXLCfNx8+1IXAWl788v2NOi+OUqrSNNHXAA0Da/HOAwmcyS9k8uLtOOM6v0op51VuoheRSBFZISLJIrJTRCaVUqaNiKwVkfMi8vQV+w6IyHYR2SIirrHitwO0bViHZwe25pvkY3yy8bCjw1FK1SCeFShjBZ4yxmwSkQAgSUS+McYklyhzEngcGFrGOfoaY47fYKxu71c9m/L9rixe/DKZrs1CaFrPz9EhKaVqgHJb9MaYTGPMJvv7XCAFCL+iTJYxZiNQWC1RKgAsFuEfIzrg5SFMWrCZs7rIuFKqAirVRy8iUUBHYH0lDjPAf0UkSUTGX+Pc40UkUUQSs7OzKxOWW2kYWIt/jIhj55Ez3P/ues4U6O9WpdS1VTjRi4g/sAh4whhzphLf0csYEw8MAiaKSO/SChljZhtjEowxCaGhoZU4vfv5WXQDZtzXkW3pOYx9dwM55zTZK6XKVqFELyJe2JL8PGPM4sp8gTEmw/4zC/gM6FLZINXVBrZryMwxnUg5cobR767j9LkLjg5JKeWkKjLqRoB3gRRjzNTKnFxE/Ow3cBERP6A/sON6AlVXuz26AbPu78Seo2e1Za+UKlNFWvQ9gbFAP/sQyS0iMlhEJojIBAARCRORdOBJ4HkRSReROkAD4EcR2QpsAP5jjFlWTXVxS31b12fm2Hh2HT3D/e+tJydfk71S6nLijA/fJCQkmMREHXJfGd8mH+PReUnENArko3Fd8fepyMhZpZSrEJEkY0xCafv0yVgXcXt0A/51XzzbM3KY8GES5626aIlSykYTvQsZEBPGa/fE8mPacZ76dCtFxc7315pS6ubTv+9dzPBOEZw4e56/fr2LurW9efGuGCwWcXRYSikH0kTvgh7p05wTeReYvWof2zJyePGuGOIigxwdllLKQbTrxkX9blAbpo7owJHT+Qyd8RPPLtzKcZ3iWCm3pIneRYkIw+Ij+P6pPjzSuxmLN2XQ9+8r+eCn/ViLih0dnlLqJtJE7+ICfL343eC2LHuiN3GRQfzpy2Tu/OePpGXlOjo0pdRNooneTbSo78/cX3Vh5phOHD97npGz1pF8pDJTFimlaipN9G5ERBjYLoxPH+mOt6eFUbPXsuXwaUeHpZSqZpro3VCzUH8+faQ7QbW9Gf32Ot74dg8pmWd0iUKlXJQmejcVGVybTx/pTmxEENO+S2XQtNX0+dtKvtiS4ejQlFJVTMfRu7GwQF/mj+9GVm4B36VksWDjYSYt2ELSwVM8f0c03p7aDlDKFei/ZEX9AF/u7dKYhRO68/AtTZm79iAjZq0lMyff0aEppaqAJnp1iZeHhd/fEc2bo+NJPZbLXf/6ia16s1apGk8TvbrK4PYNWfxYT7w9LIycvZZlOzIdHZJS6gZoolelah0WwOcTe9K2YR0mfLSJad+m6myYStVQmuhVmUIDfJj/cDfu7hjO69/uYey768k6U+DosJRSlaSJXl2Tr5cHU0d0YMo9sWw6dIpB01azYleWo8NSSlWCJnpVLhFhROdIlv6mF6EBPjz4wUZ+t3g7Z89bHR2aUqoCNNGrCmtR39Zv/0jvZizYeIhB01aReOCko8NSSpWj3EQvIpEiskJEkkVkp4hMKqVMGxFZKyLnReTpK/YNFJHdIpImIpOrMnh18/l6efC7wW359JHuCMLod9azJu24o8NSSl1DRVr0VuApY0w00A2YKCLRV5Q5CTwO/L3kRhHxAGYAg4Bo4N5SjlU1UOeoYD57rAdNQmrz0JxE1u874eiQlFJlKDfRG2MyjTGb7O9zgRQg/IoyWcaYjUDhFYd3AdKMMfuMMReABcCQKolcOVyIvw/zxnWjUZAvD36wUbtxlHJSleqjF5EooCOwvoKHhAOHS3xO54pfEiXOPV5EEkUkMTs7uzJhKQcKDfDh44e70aCOL6Nmr+PPS5PJLbjy971SypEqnOhFxB9YBDxhjKnyFSuMMbONMQnGmITQ0NCqPr2qRg3q+LLo0R4M7xTBuz/tp+/ff+CjdQfJydeEr5QzqFCiFxEvbEl+njFmcSXOnwFElvgcYd+mXEywnzev3hPLFxN7Ehlci+c/30HnP3/Lw3MT+XLrEfIvFDk6RKXcVrnTFIuIAO8CKcaYqZU8/0agpYg0xZbgRwH3VTpKVWPERgSx+NEebE3P4cutR1i67QjfJB/Dz9uDATFhDE+IoEfzeo4OUym3IuWtKiQivYDVwHag2L75OaAxgDFmpoiEAYlAHXuZs0C0MeaMiAwG3gA8gPeMMX8pL6iEhASTmJh4fTVSTqWo2LBh/0m+2JLBV9szOVNg5ZHezXh2YBs8LOLo8JRyGSKSZIxJKHWfMy4fp4neNZ23FvHnpSl8uO4gt7dtwLRRcfj56No3SlWFayV6fTJW3TQ+nh68PLQdL94Vw/e7jnHPW2vYm33W0WEp5fI00aub7oEeUbz/YBeOningjumr+WjdQV2YXKlqpF03ymGOnSng6X9vZXXqcXq1qEebsAA8LIKPp4UOkUF0bRaCv3btKFUh1+q60X9FymEa1PFlzoNdmLP2AP/6Po2kg6coNobComKKDXhahPjGdXm0b3P6tq7v6HCVqrG0Ra+cTkFhEZsOnmJ12nG+3p7JgRPnuDO2IX/8eTT1A3wdHZ5STklH3aga67y1iJkr9zFjRRq+XhZmjU2ge/MQR4ellNPRUTeqxvLx9GDS7S35+olbqBfgw6QFmzmZd8HRYSlVo2iiVzVC81B//nlvR06fK2Tyom06SkepStBEr2qMmEaBPDOgNf9NPsYnGw+Xf4BSCtBRN6qGeahXU1buyeLFL5M5nV9IUbFtlM7tbRvQLjzQ0eEp5ZT0ZqyqcY7mFDB0xk8cPVNwaZu3h4VX72nPsPgIB0amlOPoOHrlUsICfVn1bF8KrEV4e1g4d6GIx+Yl8eSnW0nNOssz/Vtj0QnTlLpEW/TKJVywFvPCkp3M33CI+gE+RIX4ERlcm7viGtGnlS5ko1yfDq9ULs/b08Ird7dj6ogO9Gppm+9+5e4sHp6TyPb0nMvKXrAW6+pXyq1oi165rJN5F7hz+mosFuE/v7mFwNpeZObk89AHiew/nsdvbmvBuF7N8PbU9o6q+bRFr9xSsJ83/xodz7EzBTz56Ra2pZ9m6IyfOHTyHJ2bBjNl2W4GTlvFqj3ZOi5fuTRN9MqlxTeuy+8Ht+W7XVkMnfETnhYLCx/tztxfdeH9X3amqNhw/3sbuOetNXy/65gmfOWStOtGuTxjDM99tp0Dx88x7d64yyZGKygs4t9J6cxcuZeM0/l0iAhk1tgEwgJ18jRVs+ikZkqVo7ComM82Z/DSl8nU9fNi3kPdaBxS29FhKVVh2kevVDm8PCyMSIhk3riu5BZYGT5zDanHch0dllJVotxELyKRIrJCRJJFZKeITCqljIjIdBFJE5FtIhJfYl+RiGyxv5ZUdQWUqkodIoP4ZHx3DDDszTU8+ckWlm47wpkCHY6paq6KPBlrBZ4yxmwSkQAgSUS+McYklygzCGhpf3UF3rL/BMg3xsRVZdBKVafWYQEsmtCD17/dw/e7s1i8OQMfTwtThscyJC7c0eEpVWnlJnpjTCaQaX+fKyIpQDhQMtEPAeYaW4f/OhEJEpGG9mOVqnEah9Tm9ZFxWIuK2XL4NFOW72bSgi0cPnmOiX1bIKJTLKiao1J99CISBXQE1l+xKxwoOW9sun0bgK+IJIrIOhEZeo1zj7eXS8zOzq5MWEpVG08PCwlRwXz4UBfu7hjO3/+7h2cXbiP91DlHh6ZUhVV4UjMR8QcWAU8YY85U4juaGGMyRKQZ8L2IbDfG7L2ykDFmNjAbbKNuKnF+paqdj6cHU0d0oHFwbaZ9l8q/k9JpFupH75ahNK/vT0RQLcLr1qJFqL9OqKacToUSvYh4YUvy84wxi0spkgFElvgcYd+GMebiz30ishLbXwRXJXqlnJ2I8H8/a8VdcY1YuTubVXuyWbDxEAWFxZfKNAr0ZUjHcIZ1DKdlgwAHRqvU/5Q7jl5snZFzgJPGmCfKKHMH8GtgMLabsNONMV1EpC5wzhhzXkTqAWuBIVfcyL2KjqNXNUVRsSE79zwZp8+xNzuPr7Znsjr1OEXFhjtjG/KXoe0JrO3l6DCVG7jR+eh7AmOB7SKyxb7tOaAxgDFmJvAVtiSfBpwDHrSXawvMEpFibPcDXi0vyStVk3hYhLBAX8ICfenUJJgRCZFk557nw3UHeXNFGkkHT/GPX3SgR4t6jg5VuTF9MlaparIt/TRPLNjCvuN5PDOgNRP7tnB0SMqF6ZOxSjlAbEQQSx/vxZC4Rvxt+W7+8d/dOmmacghdSlCpalTb25OpI+Lw9fTgn9+ncaGomMkD21BYZDiRdx5jIMDXEz9vTx2to6qNJnqlqpmHRfjrsPZ4eQqzftjHx+sPkVtgvayMCHSJCmbqyDjCg2o5KFLlqjTRK3UTWCzCy0Pa0ayeP/uP51HP34d6Ad54iJBbYOVE3gU+WneQO6evZurIOPq2ru/okJUL0ZuxSjmJfdlneWzeJnYdzWVi3+Y8cXsrvDz0NpqqGL0Zq1QN0CzUn88n9mRkQiQzVuxlxKy1HD6pUy2oG6eJXikn4uvlwWvDY5l+b0fSjp1l8LTVLNl6xNFhqRpOE71STuiuDo34atIttAoL4PH5m5mybBfFxZd3s563FpGVW0DqsVz2ZZ91UKSqJtCbsUo5qcjg2iwY340/frGDN1fuZV92Hn8d1p4f9mTzycbDrN134rLy43o1ZfKgNnhqv766giZ6pZyYl4eFV+5uT/NQf/7yVQrLk49iDDQOrs3Evs0JC6xFUC0v1u8/wTs/7mdP1ln+Oaqjzq+jLqOJXiknJyKMu6UZLRsEsGJXFv1jGtCtachlD1j9vEMjYhoF8scvdjD0zZ/45JFu1A/wdWDUypno8EqlXMjGAycZ/c56+rYOZeaYTroSlhvR4ZVKuYnOUcE8+bNWLN95jK+2H6308ZsOnSIrt6AaIlOOpIleKRczrldTYiNs3Tgn8y5U6Ji92Wd58P0NDHtzDePnJl01wkfVbJrolXIxnh4WpgyP5UxBIS8s2UnG6Xy2Hj7Nqj3Z5BYUXlb2VN4FXl6azIDXV7HxwCnujG3IlsOn+WxzhoOiV9VBb8Yq5YLahNXh131b8vq3e/iyxANXAT6ejOwcyagukSzfeYyZK/dy9oKVEZ0ieXpAa0L8vDl8Kp/Xlu1iQLsw/H00RbgCvRmrlIsqLCrm88taqbAAAA3eSURBVM0ZFBUb6vn74OVpYWFSOl9tz6TI3jVze9v6PDOgDa3D/re+7eZDp7j7zTU8emtzfjuwDQCZOfl4e1gI8fdxSF1U+W50KUGlVA3k5WHhFwmRl23r0yqUyYPa8J9tR+jYuC6do4KvOq5j47oMiw/n3dX7aRToy7KdR/kp7QQt6vuzbNIt+kBWDaRXTCk3Ex5Ui/G9m5ea5C+aPLANXh7CH77YycET5xgWH05a1lkWbUq/iZGqqlJui15EIoG5QAPAALONMdOuKCPANGwLhJ8DfmmM2WTf9wDwvL3on40xc6oufKVUdahfx5ePxnUlv7CIbk1DEIH9x/N449tUhsSF4+vl4egQVSVUpEVvBZ4yxkQD3YCJIhJ9RZlBQEv7azzwFoCIBAMvAF2BLsALIlK3imJXSlWjjo3r0qN5PSwWQUT47cA2ZOYUMHftAUeHpiqp3Ba9MSYTyLS/zxWRFCAcSC5RbAgw19ju7K4TkSARaQjcCnxjjDkJICLfAAOB+VVaC6VUtevWLIQ+rUKZsWIvIzs3JutMAR+uO8j+43lEN6pDh4ggohvWoVFQLbw9tVfYmVTqZqyIRAEdgfVX7AoHDpf4nG7fVtZ2pVQN9OzA1twx/UcGT1tNxul8vD0tNKvnx3s/7qewyDaSRwTqB/jQISKIqSPjLhuiuedYLtO+TeXpAa1pWs/PUdVwOxVO9CLiDywCnjDGnKnqQERkPLZuHxo3blzVp1dKVYGYRoGM7tqY1anH+e3ANozsHEmwnzfnrUXsPprL7qO5ZJzO59DJc3y+OYPfLd7O9FFxiAi5BYU88mES+4/nsfHAST5+uBst6vs7ukpuoUKJXkS8sCX5ecaYxaUUyQBKjuOKsG/LwNZ9U3L7ytK+wxgzG5gNtnH0FYlLKXXz/eXu9ldt8/H0IDYiiNiIoEvbmof687flu+kSVZcx3Zrw20XbOHTyHK/c3Z6p3+xh1Oy1zBvX7bIx/Kp6lNuRZh9R8y6QYoyZWkaxJcD9YtMNyLH37S8H+otIXftN2P72bUopF/don+b0bR3Ky0tT+P3nO/hq+1GeHdCa+7o2ZsH4blhEuPftdezIyHF0qC6vIndMegJjgX4issX+GiwiE0Rkgr3MV8A+IA14G3gMwH4T9mVgo/310sUbs0op12axCFNHxBEa4MPH6w/xs+gGjO/dDIAW9f355JHu+HpauPftdSQe0LRQnXQKBKVUtdqRkcOHaw/y3B1tCax1+cpXGafzGfvOeo7k5DNzTCd8vTxYsvUIK3dl0TosgLvjI+gf3UDH7VfAtaZA0ESvlHKo7Nzz3P/eBlIybWM8anl50KtlPXZk5JCZU4C/jycDYsK4K64RPZuHlDoFQ2FRMeetxW49CZvOdaOUclqhAT4sGN+NN1ekEd2oDj+LbkBtb0+Kiw3r9p/gs00ZLNt5lEWb0gnx8+axvi34Vc+oS6tnpWXl8sB7GzmSk0/L+v50jKzLHbEN6d0q1ME1cx7aoldKOb2CwiJ+2JPNR+sOsjr1OIPahTFleCy7juYybk4i3p4WRiZEsuNIDpsPnSYnv5DHbm3OU/1b42Fxj+UUtetGKeUSjDG8vXofry3bTXhQLY6dKSA8qBZzftWFyODaAJy3FvGnJcnM33CIW1rWY/qojtT183Zw5NVP14xVSrkEEWF87+Z8bJ9wrV14IAsf7XEpyYNtTP9fh7Xn1WHtWb/vJEPf/In0U+cu7TfG8NevU7j1bytIy8q97Pwn8y7wxZaMS/P1uwpt0SulaqQL1mI8LYLlGl0zmw6d4pfvbSDA14uPH+5KRN3aPP/5duZvOIyPp4U6tbxYML4bzUP9ST2Wy6/mbOTwyXym3BPLiM6RZZ7XGWnXjVLKbe3IyGHsu+vx9rTQMbIuy3YeZWLf5gyNC+fet9dhEeGJ21vx169S8PHyoG5tL/LOW/n+6Vtr1LBO7bpRSrmtduGBLBjfnaJiw7KdR3lmQGueGdCGlg0CmP9wN4qKDc99tp2I4Np88eue/OmuGI7kFDBv/aFL5zhTUMhbK/dyKu+CA2ty/XR4pVLK5bUOC+Czx3qy/3jeZcMuWzYI4JNHuvHl1kzG926Gn48n4UG16NkihBkr0hjZOZIL1mIeeG8D2zNy2Hkkh3/dF+/AmlwfbdErpdxCZHDtUsfWt6gfwP/9rBV+JR62emZAG07mXeBvy3YxctZadh/LZUBMA5Zuy+T7Xcculcs7b+XPS5NJPlLlE/pWKU30Sil1hbjIIAbENGDO2oNknM7ngwc7889742lZ358/fL6TvPNWzhQUcv97G3jnx/38dtE2ip14pI4meqWUKsXkQW25pWU9PhrXlR7N6+HtaeHVe9qTcTqfl75MZvTb69mWfprhnSLYnpHD0u2ZpZ7n9LkLPD5/MzN/2HuTa/A/2kevlFKlaFrPjw8f6nrZtk5NghnTrTEfrTuEt6eFWWM70adVfXZk5PD35bsZGBN22TKKO4/kMOGjJA6fzGfZjqP8vEMjwoNq3eyqaIteKaUq49mBbRga14gPftmZfm0a4GERJg9qw6GT5/h4/UEArEXFLNhwiHveWkOh1TDjvngMhhkr0hwSs7bolVKqEur4evHGqI6XbevTKpTuzUKY/n0aRQbe/2k/6afy6dI0mBn3xRMa4MO6fSeYv+EQj/ZpftmTvDeDtuiVUuoGiQi/G2wbqfPy0mQa1PFl1thOLHi4G6EBPgBM7NsCi0WY/l0qYJuK4dvkY/zr+1T+nXiYn9KOsy/7bLXEpy16pZSqArERQcwa24kQP28SooKv2h8W6Mvoro2Zu/Ygt7QK5cO1B9h44NRlZYL9vNn0h59VeWya6JVSqooMiAm75v5Hb23O/A2HeHz+Zur5+/DK3e0Z2rER2bnnycwpIO+8tVri0kSvlFI3Sf0AX167J5b0U/n8skfUpYe0moR40iTEr9q+VxO9UkrdREPiwm/6d5Z7M1ZE3hORLBHZUcb+uiLymYhsE5ENItKuxL4DIrJdRLaIiE5HqZRSDlCRUTcfAAOvsf85YIsxJha4H5h2xf6+xpi4sqbPVEopVb3KTfTGmFXAyWsUiQa+t5fdBUSJSIOqCU8ppdSNqopx9FuBYQAi0gVoAkTY9xngvyKSJCLjr3USERkvIokikpidnV0FYSmllIKqSfSvAkEisgX4DbAZKLLv62WMiQcGARNFpHdZJzHGzDbGJBhjEkJDr55KVCml1PW54VE3xpgzwIMAIiLAfmCffV+G/WeWiHwGdAFW3eh3KqWUqrgbbtGLSJCIeNs/jgNWGWPOiIifiATYy/gB/YFSR+4opZSqPuW26EVkPnArUE9E0oEXAC8AY8xMoC0wR0QMsBN4yH5oA+AzWyMfT+BjY8yyqq6AUkqpaxNjnG9VFBHJBg5e5+H1gONVGE5N4I51BvestzvWGdyz3pWtcxNjTKk3OJ0y0d8IEUl0tzH77lhncM96u2OdwT3rXZV11mmKlVLKxWmiV0opF+eKiX62owNwAHesM7hnvd2xzuCe9a6yOrtcH71SSqnLuWKLXimlVAma6JVSysW5TKIXkYEisltE0kRksqPjqS4iEikiK0QkWUR2isgk+/ZgEflGRFLtP+s6OtaqJiIeIrJZRJbaPzcVkfX2a/5JiSe0XYb9yfOFIrJLRFJEpLurX2sR+T/7/9s7RGS+iPi64rUuba2Psq6t2Ey313+biMRX5rtcItGLiAcwA9vkadHAvSIS7dioqo0VeMoYEw10wzZZXDQwGfjOGNMS+M7+2dVMAlJKfH4NeN0Y0wI4xf+eynYl04Blxpg2QAds9XfZay0i4cDjQIIxph3gAYzCNa/1B1y91kdZ13YQ0NL+Gg+8VZkvcolEj22ytDRjzD5jzAVgATDEwTFVC2NMpjFmk/19LrZ/+OHY6jvHXmwOMNQxEVYPEYkA7gDesX8WoB+w0F7EFescCPQG3gUwxlwwxpzGxa81tilTaomIJ1AbyMQFr3UZa32UdW2HAHONzTpsMwY3rOh3uUqiDwcOl/icbt/m0kQkCugIrAcaGGMy7buOYptryJW8ATwLFNs/hwCnjTFW+2dXvOZNgWzgfXuX1Tv2CQJd9lrbZ7z9O3AIW4LPAZJw/Wt9UVnX9oZynKskercjIv7AIuAJ+1TRlxjbmFmXGTcrIncCWcaYJEfHcpN5AvHAW8aYjkAeV3TTuOC1rout9doUaAT4ce2lTF1WVV5bV0n0GUBkic8R9m0uSUS8sCX5ecaYxfbNxy7+KWf/meWo+KpBT+AuETmArVuuH7a+6yD7n/fgmtc8HUg3xqy3f16ILfG78rW+HdhvjMk2xhQCi7Fdf1e/1heVdW1vKMe5SqLfCLS035n3xnbzZomDY6oW9r7pd4EUY8zUEruWAA/Y3z8AfHGzY6suxpjfGWMijDFR2K7t98aY0cAKYLi9mEvVGcAYcxQ4LCKt7ZtuA5Jx4WuNrcumm4jUtv+/frHOLn2tSyjr2i4B7rePvukG5JTo4imfMcYlXsBgYA+wF/i9o+Opxnr2wvbn3DZgi/01GFuf9XdAKvAtEOzoWKup/rcCS+3vmwEbgDTg34CPo+OrhvrGAYn26/05UNfVrzXwIrAL20JFHwI+rnitgfnY7kMUYvvr7aGyri0g2EYW7gW2YxuVVOHv0ikQlFLKxblK141SSqkyaKJXSikXp4leKaVcnCZ6pZRycZrolVLKxWmiV0opF6eJXimlXNz/A9jGxI9TNiQkAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_list, label='Training loss')\n",
    "#plt.plot(val_losses, label='Validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3438\n"
     ]
    }
   ],
   "source": [
    "outputs = model(val_x.float())\n",
    "_, predicted = torch.max(outputs.data, 1)\n",
    "correct = (predicted == val_y).sum().item()\n",
    "\n",
    "#print(correct.shape)\n",
    "\n",
    "# for i in range(outputs.shape[0]):\n",
    "#     if((predicted[i] == val_y[i])):\n",
    "#         pass\n",
    "        #print(trainset.classes[testset.targets[i]])\n",
    "        #plt.imshow(testset.data[i])\n",
    "        #plt.show()\n",
    "        \n",
    "print(correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorboard\n",
    "TensorBoard provides visualization and tooling for machine learning experimentation:\n",
    "- Tracking and visualizing metrics such as loss and accuracy\n",
    "- Visualizing the model graph (ops and layers)\n",
    "- Viewing histograms of weights, biases, or other tensors as they change over time\n",
    "- Projecting embeddings to a lower dimensional space\n",
    "- Displaying images, text, and audio data\n",
    "- Profiling programs\n",
    "\n",
    "Tensorboard worked originally with Tensorflow but can now be used with PyTorch as well.  \n",
    "You can embed a tensorboard widget in a Jupyter Notebook, although if you're not using Google Colab we recommend that you open tensorboard separately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get started with Tensorboard, please read the following pages:\n",
    "\n",
    "PyTorch related:\n",
    "1. https://pytorch.org/tutorials/intermediate/tensorboard_tutorial.html\n",
    "1. https://becominghuman.ai/logging-in-tensorboard-with-pytorch-or-any-other-library-c549163dee9e\n",
    "1. https://towardsdatascience.com/https-medium-com-dinber19-take-a-deeper-look-at-your-pytorch-model-with-the-new-tensorboard-built-in-513969cf6a72\n",
    "1. https://pytorch.org/docs/stable/tensorboard.html\n",
    "1. https://github.com/yunjey/pytorch-tutorial/tree/master/tutorials/04-utils/tensorboard\n",
    "\n",
    "Tensorflow related:\n",
    "1. https://itnext.io/how-to-use-tensorboard-5d82f8654496\n",
    "1. https://www.datacamp.com/community/tutorials/tensorboard-tutorial\n",
    "1. https://medium.com/@anthony_sarkis/tensorboard-quick-start-in-5-minutes-e3ec69f673af\n",
    "1. https://www.guru99.com/tensorboard-tutorial.html\n",
    "1. https://www.youtube.com/watch?time_continue=1&v=s-lHP8v9qzY&feature=emb_logo\n",
    "1. https://www.youtube.com/watch?v=pSexXMdruFM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting Tensorboard\n",
    "Jupyter Notebook has extensions for displaying TensorBoard inside the notebook. Still, I recommend that you run it separately, as it tends to get stuck in notebooks.\n",
    "\n",
    "The syntax to load TensorBoard in a notebook is this:\n",
    "```python\n",
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir ./logs\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the shell, you can instead run:\n",
    "```\n",
    "tensorboard --logdir ./logs\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mConvolution model - Step by Step - v1.ipynb\u001b[m\u001b[m*\r\n",
      "NN_in_pytorch.ipynb\r\n",
      "\u001b[34mdata\u001b[m\u001b[m/\r\n",
      "\u001b[34mimages\u001b[m\u001b[m/\r\n",
      "\u001b[34mruns\u001b[m\u001b[m/\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T03:22:21.503129Z",
     "start_time": "2020-03-12T03:22:18.807319Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ERROR: Failed to launch TensorBoard (exited with 1).\n",
       "Contents of stderr:\n",
       "Traceback (most recent call last):\n",
       "  File \"/Library/Frameworks/Python.framework/Versions/3.7/bin/tensorboard\", line 10, in <module>\n",
       "    sys.exit(run_main())\n",
       "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorboard/main.py\", line 66, in run_main\n",
       "    app.run(tensorboard.main, flags_parser=tensorboard.configure)\n",
       "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/absl/app.py\", line 293, in run\n",
       "    flags_parser,\n",
       "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/absl/app.py\", line 362, in _run_init\n",
       "    flags_parser=flags_parser,\n",
       "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/absl/app.py\", line 212, in _register_and_parse_flags_with_usage\n",
       "    args_to_main = flags_parser(original_argv)\n",
       "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorboard/program.py\", line 215, in configure\n",
       "    flags = base_parser.parse_args(argv[1:])  # Strip binary name from argv.\n",
       "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/argparse.py\", line 1745, in parse_args\n",
       "    args, argv = self.parse_known_args(args, namespace)\n",
       "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/absl/flags/argparse_flags.py\", line 169, in parse_known_args\n",
       "    args, namespace)\n",
       "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/argparse.py\", line 1777, in parse_known_args\n",
       "    namespace, args = self._parse_known_args(args, namespace)\n",
       "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/argparse.py\", line 2012, in _parse_known_args\n",
       "    ', '.join(required_actions))\n",
       "TypeError: sequence item 0: expected str instance, NoneType found"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir ./runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show images using TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T03:22:25.305404Z",
     "start_time": "2020-03-12T03:22:22.367810Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the model graph\n",
    "You can print a network object to find useful information about it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T03:39:13.437035Z",
     "start_time": "2020-03-12T03:39:13.433000Z"
    }
   },
   "outputs": [],
   "source": [
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorBoard can help visualize the network graph. It takes practice to read these.  \n",
    "\n",
    "Write the graph to TensorBoard and review it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T03:22:27.132650Z",
     "start_time": "2020-03-12T03:22:27.080267Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use the package `torchsummary` for a fuller info on the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T03:39:34.927085Z",
     "start_time": "2020-03-12T03:39:30.883979Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchsummary\n",
      "  Downloading https://files.pythonhosted.org/packages/7d/18/1474d06f721b86e6a9b9d7392ad68bed711a02f3b61ac43f13c719db50a6/torchsummary-1.5.1-py3-none-any.whl\n",
      "Installing collected packages: torchsummary\n",
      "Successfully installed torchsummary-1.5.1\n"
     ]
    }
   ],
   "source": [
    "!pip install torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T03:40:32.330002Z",
     "start_time": "2020-03-12T03:40:32.304145Z"
    }
   },
   "outputs": [],
   "source": [
    "channels=3; H=32; W=32\n",
    "from torchsummary import summary\n",
    "summary(net, input_size=(channels, H, W))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the network\n",
    "Next, we'll train the network. In the training loop, log relevant metrics that would allow you to plot in TensorBoard:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The network loss\n",
    "1. Train and test error\n",
    "1. Average weight in the first layer\n",
    "1. Histogram of weights in the first layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T02:25:56.483936Z",
     "start_time": "2020-03-12T02:17:35.780050Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision-Recall Curve\n",
    "Use TensorBoard to plot the precision-recall curve:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Model Errors\n",
    "A valuable practice is to review errors made by the model in the test set. These might reveal cases of bad preprocessing or lead to come up with improvements to your original model.\n",
    "\n",
    "Show 12 images of errors made by the model. For each, display the true and predicted classes, and the model confidence in its answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Normalization\n",
    "In this section, we'll add a Batch Norm layer to your network.  \n",
    "Use TensorBoard to compare the network's convergence (train and validation loss) with and without Batch Normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T02:02:02.225508Z",
     "start_time": "2020-03-12T02:02:02.204005Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use TensorBoard to plot the distribution of activations with and without Batch Normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation\n",
    "Augmenting the data is a useful trick to increase the size of the training set and reduce the generalization error.  \n",
    "\n",
    "Useful resources: \n",
    "- [Explanation about augmentation](https://www.analyticsvidhya.com/blog/2019/12/image-augmentation-deep-learning-pytorch/)\n",
    "- The [torchvision transforms documentation](https://pytorch.org/docs/stable/torchvision/transforms.html)\n",
    "- The [albumentations](https://github.com/albumentations-team/albumentations) repo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to think which transformation can be useful for data augmentation for our task?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply 1 or 2 basic transformations and check how they affect the network's performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer learning using a NN pre-trained on ImageNet\n",
    "In this section, we will use a pretrained network and build a classifier using it to predict the labels of our task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might find these resources useful:\n",
    "- https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html\n",
    "- https://towardsdatascience.com/transfer-learning-with-convolutional-neural-networks-in-pytorch-dd09190245ce\n",
    "- https://www.analyticsvidhya.com/blog/2019/10/how-to-master-transfer-learning-using-pytorch/\n",
    "- https://heartbeat.fritz.ai/transfer-learning-with-pytorch-cfcb69016c72"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use a frozen pre-trained network\n",
    "Use a VGG-16 network, including its weights pretrained on ImageNet.  \n",
    "Use the pretrained network to obtain the distributed representation in the final layer (the one before the output softmax layer). Freeze the network weights, and add 2 fully connected layers on top of it to classify the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine tuning the weights\n",
    "In this section, we'll unfreeze the pre-trained weights of the network and allow them to change.  \n",
    "Be careful - when fine-tuning a network, there is a risk that our attempt to allow the network to adapt to the new domain will lead to a \"catastrophic forgetting\" of what it had previously learnt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suggested Resources\n",
    "1. A good explanation of the different losses - https://gombru.github.io/2019/04/03/ranking_loss/\n",
    "1. A repo with code implementing CNN classifiers, Siamese networks and Triplet loss with different selection regimes for the MNIST and Fashion-MNIST datasets - https://github.com/adambielski/siamese-triplet\n",
    "1. There are several resources online for the VGG-Face network (see https://www.robots.ox.ac.uk/~vgg/publications/2015/Parkhi15/parkhi15.pdf), that include pre-trained weights on a face recognition dataset. The weights are here - http://www.robots.ox.ac.uk/~vgg/software/vgg_face/, and PyTorch models are here - http://www.robots.ox.ac.uk/~albanie/pytorch-models.html, and you can also check out https://github.com/prlz77/vgg-face.pytorch and https://github.com/claudio-unipv/vggface-pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0b4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
